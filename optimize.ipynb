{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import catboost\n",
    "import xgboost\n",
    "import lightgbm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "# trainから id = 170514を削除する (外れ値)\n",
    "train = train[train[\"id\"] != 170514]\n",
    "train = train.reset_index(drop = True)\n",
    "\n",
    "# 説明変数と目的変数の分離\n",
    "# 列の抜き出し\n",
    "features = train.columns\n",
    "features = features.drop([\"id\", \"target\"])\n",
    "\n",
    "# 分離\n",
    "train_target = train[\"target\"]\n",
    "train_id = train[\"id\"]\n",
    "test_id = test[\"id\"]\n",
    "train = train[features]\n",
    "test = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans法によるラベリング(特徴量エンジニアリング)\n",
    "km = KMeans(n_clusters=2, random_state=0)\n",
    "km.fit(train)\n",
    "km_train = pd.DataFrame(km.predict(train), columns = [\"km_cluster\"])\n",
    "km_test = pd.DataFrame(km.predict(test), columns = [\"km_cluster\"])\n",
    "\n",
    "# 結合\n",
    "train = pd.concat([train, km_train], axis = 1)\n",
    "test = pd.concat([test, km_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 決定木系モデル用のデータを作成\n",
    "train_dt = train.copy()\n",
    "test_dt = test.copy()\n",
    "\n",
    "# 混合ガウス分布による特徴量のラベリング(特徴量エンジニアリング)\n",
    "def get_gmm_class_feature(feat, train_df, test_df, n):\n",
    "    gmm = GaussianMixture(n_components=n, random_state=1234)\n",
    "    gmm.fit(train_df[feat].values.reshape(-1, 1))\n",
    "    train_df[f'{feat}_class'] = gmm.predict(train_df[feat].values.reshape(-1, 1))\n",
    "    test_df[f'{feat}_class'] = gmm.predict(test_df[feat].values.reshape(-1, 1))\n",
    "\n",
    "get_gmm_class_feature('cont1', train_dt, test_dt, 4)\n",
    "get_gmm_class_feature('cont2', train_dt, test_dt, 10)\n",
    "get_gmm_class_feature('cont3', train_dt, test_dt, 6)\n",
    "get_gmm_class_feature('cont4', train_dt, test_dt, 4)\n",
    "get_gmm_class_feature('cont5', train_dt, test_dt, 3)\n",
    "get_gmm_class_feature('cont6', train_dt, test_dt, 2)\n",
    "get_gmm_class_feature('cont7', train_dt, test_dt, 3)\n",
    "get_gmm_class_feature('cont8', train_dt, test_dt, 4)\n",
    "get_gmm_class_feature('cont9', train_dt, test_dt, 4)\n",
    "get_gmm_class_feature('cont10', train_dt, test_dt, 8)\n",
    "get_gmm_class_feature('cont11', train_dt, test_dt, 5)\n",
    "get_gmm_class_feature('cont12', train_dt, test_dt, 4)\n",
    "get_gmm_class_feature('cont13', train_dt, test_dt, 6)\n",
    "get_gmm_class_feature('cont14', train_dt, test_dt, 6)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 線形回帰、K近傍法用にデータを加工する\n",
    "train_l = train_dt.copy()\n",
    "test_l = test_dt.copy()\n",
    "\n",
    "# ダミー変数化\n",
    "for i in range(1,15):\n",
    "    temp = pd.get_dummies(train_l[\"cont{}_class\".format(str(i))], drop_first = True)\n",
    "    train_l = pd.concat([train_l, temp], axis = 1)\n",
    "    del train_l[\"cont{}_class\".format(str(i))]\n",
    "\n",
    "for i in range(1,15):\n",
    "    temp = pd.get_dummies(test_l[\"cont{}_class\".format(str(i))], drop_first = True)\n",
    "    test_l = pd.concat([test_l, temp], axis = 1)\n",
    "    del test_l[\"cont{}_class\".format(str(i))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "X_train_dt, X_val_dt, y_train_dt, y_val_dt = train_test_split(train_dt, train_target, test_size = 0.25, random_state = 1234)\n",
    "X_train_l, X_val_l, y_train_l, y_val_l = train_test_split(train_l, train_target, test_size = 0.25, random_state = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoostのハイパーパラメーターチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_cat(trial, X_train = X_train_dt, y_train = y_train_dt, X_val = X_val_dt, y_val = y_val_dt):\n",
    "    \n",
    "    params = {\n",
    "              \"learning_rate\" : trial.suggest_categorical(\"learning_rate\", [0.01, 0.03, 0.05, 0.1, 0.15, 0.2]),\n",
    "              \"n_estimators\" : trial.suggest_categorical(\"n_estimators\", [100, 500, 1000, 2000, 3000, 4000]),\n",
    "              \"max_depth\" : trial.suggest_int(\"max_depth\", 5,16),\n",
    "              \"random_state\" : 1234\n",
    "    }\n",
    "\n",
    "    model = catboost.CatBoostRegressor(**params)\n",
    "    model.fit(X_train, y_train, eval_set = [(X_val, y_val)], early_stopping_rounds = 100, verbose = False)\n",
    "\n",
    "    preds = model.predict(X_val)\n",
    "\n",
    "    rmse = mean_squared_error(y_val, preds, squared = False)\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective_cat, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoostのハイパーパラメーターチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_xgb(trial, X_train = X_train_dt, y_train = y_train_dt, X_val = X_val_dt, y_val = y_val_dt):\n",
    "    \n",
    "    params = {\n",
    "              \"learning_rate\" : trial.suggest_categorical(\"learning_rate\", [0.01, 0.03, 0.05, 0.1, 0.15, 0.2]),\n",
    "              \"n_estimators\" : trial.suggest_categorical(\"n_estimators\", [100, 500, 1000, 2000, 3000, 4000]),\n",
    "              \"max_depth\" : trial.suggest_int(\"max_depth\", 5, 30),\n",
    "              \"alpha\" : trial.suggest_uniform(\"alpha\", 0, 10),\n",
    "              \"random_state\" : 1234\n",
    "    }\n",
    "\n",
    "    model = xgboost.XGBRegressor(**params)\n",
    "    model.fit(X_train, y_train, eval_set = [(X_val, y_val)], early_stopping_rounds = 100, verbose = False)\n",
    "\n",
    "    preds = model.predict(X_val)\n",
    "\n",
    "    rmse = mean_squared_error(y_val, preds, squared = False)\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective_xgb, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBMのハイパーパラメーターチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgbm(trial, X_train = X_train_dt, y_train = y_train_dt, X_val = X_val_dt, y_val = y_val_dt):\n",
    "    \n",
    "    params = {\n",
    "              \"learning_rate\" : trial.suggest_categorical(\"learning_rate\", [0.01, 0.03, 0.05, 0.1, 0.15, 0.2]),\n",
    "              \"n_estimators\" : trial.suggest_categorical(\"n_estimators\", [100, 500, 1000, 2000, 3000, 4000]),\n",
    "              \"max_depth\" : trial.suggest_int(\"max_depth\", 5, 30),\n",
    "              \"alpha\" : trial.suggest_uniform(\"alpha\", 0, 10),\n",
    "              \"random_state\" : 1234,\n",
    "              \"metric\":\"root_mean_squared_error\",\n",
    "    }\n",
    "\n",
    "    model = lightgbm.LGBMRegressor(**params)\n",
    "    model.fit(X_train, y_train, eval_set = [(X_val, y_val)], early_stopping_rounds = 100, verbose = False)\n",
    "\n",
    "    preds = model.predict(X_val)\n",
    "\n",
    "    rmse = mean_squared_error(y_val, preds, squared = False)\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective_lgbm, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestのハイパーパラメーターチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_rf(trial, X_train = X_train_dt, y_train = y_train_dt, X_val = X_val_dt, y_val = y_val_dt):\n",
    "    params = {\n",
    "              \"n_estimators\" : trial.suggest_categorical(\"n_estimators\", [100, 500, 1000]),\n",
    "              \"max_depth\" : trial.suggest_int(\"max_depth\", 5, 30),\n",
    "              \"random_state\":1234\n",
    "    }\n",
    "\n",
    "    model = RandomForestRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    preds = model.predict(X_val)\n",
    "\n",
    "    rmse = mean_squared_error(y_val, preds, squared = False)\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective_rf, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge回帰のハイパーパラメーターチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(0, 100, 0.1)\n",
    "results = []\n",
    "for i in alphas:\n",
    "    ri = Ridge(alpha = i)\n",
    "    ri.fit(X_train_l, y_train_l)\n",
    "    y_pred = ri.predict(X_val_l)\n",
    "    result = np.sqrt(mean_squared_error(y_pred, y_val_l))\n",
    "    print(\"alpha{} : \".format(i), result)\n",
    "    results.append(result)\n",
    "    \n",
    "print(\"Best alpha : \"+str(np.argmin(results)/10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K近傍法のハイパーパラメーターチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_k = []\n",
    "list_rmse = []\n",
    "for k in range(1, 101, 5):\n",
    "    \n",
    "    # KNeighborsRegressor\n",
    "    knr = KNeighborsRegressor(n_neighbors=k)\n",
    "    knr.fit(X_train_l, y_train_l)\n",
    "\n",
    "    # 予測　\n",
    "    y_pred = knr.predict(X_val_l)\n",
    "\n",
    "    # 評価\n",
    "    # 平方根平均二乗誤差（RMSE）\n",
    "    score_rmse = np.sqrt(mean_squared_error(y_val_l, y_pred))\n",
    "    \n",
    "    print(\"k={} : {}\".format(str(k), str(score_rmse)))\n",
    "\n",
    "    list_k.append(k)\n",
    "    list_rmse.append(score_rmse)\n",
    "\n",
    "# プロット\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"rmse\")\n",
    "plt.plot(list_k, list_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
